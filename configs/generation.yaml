# ───── pipeline ─────
model_name: meta-llama/Llama-3.2-3B-Instruct        
tokenizer_name:                                     # leave blank = same as model
torch_dtype: bfloat16
device_map: auto

# ───── generation ─────
max_new_tokens: 1024
do_sample: False
temperature: 0.0

# ───── rag ─────
max_content_length: 12000

# ───── data ─────
data: ./data/cve_data.csv